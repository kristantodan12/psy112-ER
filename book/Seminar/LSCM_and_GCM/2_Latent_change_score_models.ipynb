{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Change Score Models (LCSMs)\n",
    "\n",
    "### 1. Introduction\n",
    "LCSMs represent a powerful extension of the observed-level change score models covered in the previous tutorial. The main difference between these two classes of models is the inclusion of **latent variables** for which we aim to estimate the change. The distinction between observed and latent variables is crucial as it represents one of the core advantages of using structural equation modeling (SEM) in general. When estimating latent variables measured by a set of indicators (observed variables at the measurement level), we are correcting for **measurement error**. In other words, by including latent variables in our analyses, we achieve results at the \"true\" score level. Consequently, with LCSMs we can assess the change of the true score on a given construct over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\.conda\\envs\\psy112ER\\Lib\\site-packages\\rpy2\\robjects\\packages.py:367: UserWarning: The symbol 'quartz' is not in this R namespace/package.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "## Specify R environment for rpy2\n",
    "#import os\n",
    "#os.environ['R_HOME'] = r'C:/Program Files/R/R-4.4.3'  # Replace with your R path\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import Formula\n",
    "import contextlib\n",
    "# Ipython extension for plotting\n",
    "%load_ext rpy2.ipython\n",
    "########################################################\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Working Example 1\n",
    "\n",
    "`fairplayer` is a data frame that contains information from a research project targeting **bullying** in a school: The variable names consist of one letter indicating the measurement source (s: self-report, t: teacher-report), two letters indicating each construct being measured (EM: empathy, RA: relational aggression, SI: social intelligence), a number indicating the item number on the scale, and a \"t\" followed by a number indicating the measurement occasion (time-point) (for more details see https://rdrr.io/cran/stuart/man/fairplayer.html). In addition, the variables IGS (short intervention) and IGL (long intervention) represent the kind of intervention groups to which the students belonged. These variables are dummy coded with 1 representing membership and 0 representing no membership. Thus, students with a 0 in both variables belong to the control group and did not experience any intervention. \n",
    "\n",
    "In other words, we have a data frame including 3 outcome variables (EM: empathy, RA: relational aggression, SI: social intelligence) measured by 2 different methods (self-report or teacher-report). 3 time-points (measurement occasions) for 3 different groups (1 control and 2 intervention groups). \n",
    "\n",
    "Please inspect the data frame to get familiar with the information that is included. Understanding the information in this data frame will help you to follow the modeling procedure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ratee  IGL  IGS  sEM01at1  sEM02at1  sEM03at1  tEM01at1  tEM02at1  \\\n",
      "1    1.0  1.0  0.0  3.666667  3.333333       4.5  4.666667  3.666667   \n",
      "2    2.0  1.0  0.0  3.666667  4.333333       3.5  4.333333  4.000000   \n",
      "3    3.0  1.0  0.0  3.000000  2.666667       2.5  4.333333  3.666667   \n",
      "4    4.0  1.0  0.0  4.666667  4.666667       5.0  3.333333  3.333333   \n",
      "5    5.0  1.0  0.0  3.000000  3.000000       3.5  1.333333  2.333333   \n",
      "\n",
      "   tEM03at1  sEM01at2  ...  sRA03at2  tRA01at2  tRA02at2  tRA03at2  sRA01at3  \\\n",
      "1       5.0  3.666667  ...       1.0       1.0       2.0       1.0       1.0   \n",
      "2       4.0  4.666667  ...       1.0       1.0       2.0       1.0       1.0   \n",
      "3       4.0  2.666667  ...       1.0       1.0       1.5       1.0       1.5   \n",
      "4       3.0  4.666667  ...       1.0       2.5       3.0       1.0       1.0   \n",
      "5       1.0  3.000000  ...       1.0       2.0       3.0       2.0       1.5   \n",
      "\n",
      "   sRA02at3  sRA03at3  tRA01at3  tRA02at3  tRA03at3  \n",
      "1       2.5       1.0       1.0       2.0       1.0  \n",
      "2       1.0       1.0       1.0       1.5       1.0  \n",
      "3       2.0       2.0       1.0       1.5       1.0  \n",
      "4       1.5       1.0       2.0       3.0       2.0  \n",
      "5       1.0       1.0       2.0       2.0       2.0  \n",
      "\n",
      "[5 rows x 57 columns]\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file using a relative path\n",
    "fairplayer = pd.read_csv(\"../LSCM_and_GCM/Datasets/fairplayer.csv\")\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(fairplayer.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model specification\n",
    "\n",
    "Recall what you learned in the last tutorial. The only difference in specification of LCSMs as compared to CSMs is that we need to define latent variables measured by their multiple indicators (thus, the measurement models). Accordingly, we must specify factor loadings for the construct of interest. In addition, the latent **- now second order -** change score factor will be regressed onto the time 1 latent factor and explain variance in the time 2 latent factor. \n",
    "\n",
    "In the following example we are interested in assessing the change in *empathy* from time-point 1 to time-point 2. We fit the model using `lavaan`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: This is lavaan 0.6-19\n",
      "lavaan is FREE software! Please report any bugs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Activate pandas2ri for automatic conversion\n",
    "pandas2ri.activate()\n",
    "\n",
    "# Import the lavaan package in R\n",
    "ro.r('library(lavaan)')\n",
    "\n",
    "# Import semPlot for plotting SEM paths\n",
    "ro.r('library(semPlot)')\n",
    "\n",
    "# Load the dataset into R\n",
    "ro.globalenv['fairplayer'] = pandas2ri.py2rpy(fairplayer)\n",
    "\n",
    "# Define the SEM model\n",
    "ro.r('''\n",
    "lcsm1 <- '\n",
    "\n",
    "# Defining a latent variable representing the construct Empathy at time 1 \n",
    "emp1 =~ sEM01at1 + sEM02at1 + sEM03at1  \n",
    "\n",
    "# Defining a latent variable representing the construct Empathy at time 2\n",
    "emp2 =~ sEM01at2 + sEM02at2 + sEM03at2 \n",
    "\n",
    "# Fixing the change score loading to 1\n",
    "change =~ 1*emp2\n",
    "\n",
    "#Fixing the regression of time 2 on time 1 to 1\n",
    "emp2 ~ 1*emp1\n",
    "\n",
    "#Fixing post-intervention score residual variance to 0\n",
    "emp2 ~~ 0 * emp2  \n",
    "\n",
    "#Fixing the intercept of one indicator per time-point to 0 to identify the mean structure\n",
    "sEM01at2 ~ 0*1\n",
    "sEM01at1 ~ 0*1\n",
    "\n",
    "\n",
    "# Freely estimate the means of the change score phantom variable and the baseline (time 1). Per default, these are fixed to zero in lavaan\n",
    "change ~ 1 \n",
    "emp1 ~ 1\n",
    "\n",
    "# Specify a covariance between the change score latent variable and the baseline (time 1)\n",
    "change ~~ emp1\n",
    "' \n",
    "''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Fitting\n",
    "\n",
    "We can now fit the model specified above by using the `sem()` function. Then we examine the estimated parameters and plot a graphical overview of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lavaan 0.6-19 ended normally after 63 iterations\n",
      "\n",
      "  Estimator                                         ML\n",
      "  Optimization method                           NLMINB\n",
      "  Number of model parameters                        19\n",
      "\n",
      "                                                  Used       Total\n",
      "  Number of observations                           120         143\n",
      "\n",
      "Model Test User Model:\n",
      "                                                      \n",
      "  Test statistic                                51.469\n",
      "  Degrees of freedom                                 8\n",
      "  P-value (Chi-square)                           0.000\n",
      "\n",
      "Model Test Baseline Model:\n",
      "\n",
      "  Test statistic                               348.774\n",
      "  Degrees of freedom                                15\n",
      "  P-value                                        0.000\n",
      "\n",
      "User Model versus Baseline Model:\n",
      "\n",
      "  Comparative Fit Index (CFI)                    0.870\n",
      "  Tucker-Lewis Index (TLI)                       0.756\n",
      "\n",
      "Loglikelihood and Information Criteria:\n",
      "\n",
      "  Loglikelihood user model (H0)               -670.305\n",
      "  Loglikelihood unrestricted model (H1)       -644.571\n",
      "                                                      \n",
      "  Akaike (AIC)                                1378.610\n",
      "  Bayesian (BIC)                              1431.573\n",
      "  Sample-size adjusted Bayesian (SABIC)       1371.504\n",
      "\n",
      "Root Mean Square Error of Approximation:\n",
      "\n",
      "  RMSEA                                          0.213\n",
      "  90 Percent confidence interval - lower         0.160\n",
      "  90 Percent confidence interval - upper         0.270\n",
      "  P-value H_0: RMSEA <= 0.050                    0.000\n",
      "  P-value H_0: RMSEA >= 0.080                    1.000\n",
      "\n",
      "Standardized Root Mean Square Residual:\n",
      "\n",
      "  SRMR                                           0.063\n",
      "\n",
      "Parameter Estimates:\n",
      "\n",
      "  Standard errors                             Standard\n",
      "  Information                                 Expected\n",
      "  Information saturated (h1) model          Structured\n",
      "\n",
      "Latent Variables:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n",
      "  emp1 =~                                                               \n",
      "    sEM01at1          1.000                               0.485    0.681\n",
      "    sEM02at1          1.134    0.165    6.854    0.000    0.549    0.747\n",
      "    sEM03at1          1.414    0.195    7.235    0.000    0.685    0.819\n",
      "  emp2 =~                                                               \n",
      "    sEM01at2          1.000                               0.508    0.726\n",
      "    sEM02at2          1.187    0.150    7.918    0.000    0.603    0.826\n",
      "    sEM03at2          1.215    0.165    7.382    0.000    0.617    0.747\n",
      "  change =~                                                             \n",
      "    emp2              1.000                               0.608    0.608\n",
      "\n",
      "Regressions:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n",
      "  emp2 ~                                                                \n",
      "    emp1              1.000                               0.953    0.953\n",
      "\n",
      "Covariances:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n",
      "  emp1 ~~                                                               \n",
      "    change           -0.036    0.040   -0.896    0.370   -0.240   -0.240\n",
      "\n",
      "Intercepts:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n",
      "   .sEM01at2          0.000                               0.000    0.000\n",
      "   .sEM01at1          0.000                               0.000    0.000\n",
      "    change            0.083    0.071    1.180    0.238    0.270    0.270\n",
      "    emp1              3.883    0.065   59.758    0.000    8.014    8.014\n",
      "   .sEM02at1         -0.616    0.646   -0.954    0.340   -0.616   -0.838\n",
      "   .sEM03at1         -1.725    0.763   -2.260    0.024   -1.725   -2.062\n",
      "   .sEM02at2         -0.963    0.598   -1.611    0.107   -0.963   -1.320\n",
      "   .sEM03at2         -0.998    0.657   -1.520    0.129   -0.998   -1.209\n",
      "\n",
      "Variances:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n",
      "   .emp2              0.000                               0.000    0.000\n",
      "   .sEM01at1          0.272    0.042    6.432    0.000    0.272    0.537\n",
      "   .sEM02at1          0.239    0.041    5.778    0.000    0.239    0.442\n",
      "   .sEM03at1          0.230    0.050    4.597    0.000    0.230    0.329\n",
      "   .sEM01at2          0.231    0.038    6.131    0.000    0.231    0.472\n",
      "   .sEM02at2          0.169    0.037    4.625    0.000    0.169    0.317\n",
      "   .sEM03at2          0.301    0.051    5.901    0.000    0.301    0.441\n",
      "    emp1              0.235    0.060    3.912    0.000    1.000    1.000\n",
      "    change            0.095    0.030    3.128    0.002    1.000    1.000\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAB9AAAASwCAMAAACU+iGMAAAAyVBMVEUAAAAAADoAAGYAOjoAOmYAOpAAZpAAZrY6AAA6ADo6AGY6OgA6Ojo6OmY6ZpA6ZrY6kLY6kNtmAABmADpmOgBmOjpmZjpmZmZmZpBmkJBmkLZmtpBmtttmtv+AgICQOgCQZgCQZjqQZraQkDqQtpCQttuQtv+Q29uQ2/+2ZgC2Zjq2kDq2kGa2kJC2tma2ttu225C229u22/+2/9u2///bkDrbtmbbtpDb27bb29vb2//b////tmb/25D/27b/29v//7b//9v///94XcO+AAAACXBIWXMAABcRAAAXEQHKJvM/AAAgAElEQVR4nO3d62Ij15kearRkp3t8kEaKPDt2LCpORtnTHieZUbpt71G3reb9X9QmQJDEoQp1WoevVj3PD6lJkMDiwlvfSxy5uwcAVm9XewEAwHIKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKHQAaoNABoAEKPaHdznYSkWQSlGgmZTMTkk1ikkyCEs2kbGY6D8kUTgKSTIISzbTsZTqySUySSVCimZa9TOaQS+EkHMkkKNFMzFamsjtm044SjGQSk6GZmp1M5RhK2SQYySQo0UzNTibynEnhJJanREomsRiaydnIRGSTmCSToEQzORuZxkkihZNATh6glEwiMTTTs49pyCYxSSZBiWZ69jGJszwKJ2FIJkGJZga2MYXdRTbtKkFIJjEZmjnYxRQuwiibBCGZBCWaOdjFBK6yKJzEcJlEySQGQzMLm5iAbBKTZBKUaGZhE5frSKJwEkDHA5OSSQSGZh72cLGup3N4igcBSCYxGZqZ2MLFOmMom1QnmQQlmpnYwqV6Uiic1NadQcmkNkMzFzu4lGwSk2QSlGjmYgcX6s2gcFJXXwIlk7oMzWxs4EKySUySSVCimY0NXOZGAoWTmvrzJ5nUZGjmY/8WOX+lxcdfvOs9DYqSTGIyNDOyfYucxe/D7rN3vSdCSWeTUTKJw9DMyPYtcZa+t6/++eyXTeGkntPsSSZxGJo52b0lLsL3UTaJQTIJSjRzsnsLXGbvMpvCSSUDU1MyqcTQzMrmzXf1BI6ObNpfKpBMYjI087J3810F7yqbftukisGpKZlUYWjmZe9mu87ddTaFkwpGTE3JpAJDMzNbN5tsEtP1nZaSSQiGZma2bq6RqRNOShuXOcmkNEMzNzs3l2wSk2QSlGjmZudmGp054aSssYmTTMoyNLOzcfOMf22FV2FQlGQSk6GZn32bZ0LgZJOSxudNMinJ0MzPvs0yKW/CSTlT0iaZlGNoFmDbZpFNglLoxGRoFmDb5thNVXvBbIVkEpOhWYJdm0M2CUoyicnQLMGuQfPu7mqvADqJZlIKPSHZJCbJJCjRTEqhJySbxCSZBCWaSSn0hGSTmCSToEQzKYWekGwSk2QSlGgmpdATkk1ikkyCEs2kFHpCsklMkklQopmUQk9INolJMglKNJNS6AnJJjFJJkGJZlIKPSHZJCbJJCjRTEqhQ/NMTYISzaQUOjTP1CQo0UxKoUPzTE2CEs2kFDo0z9QkKNFMSqFD80xNghLNpBQ6NM/UJCjRTEqhQ/NMTYISzaQUekKySUySSVCimZRCT0g2iUkyCUo0k1LoCckmMUkmQYlmUgo9IdkkJskkKNFMSqEnJJvEJJkEJZpJKfSEZJOYJJOgRDMphZ6QbBKTZBKUaCal0BOSTWKSTIISzaQUekKySUySSVCimZRCh+aZmgQlmkkpdGieqUlQopmUQofmmZoEJZpJKXRonqlJUKKZlEKH5pmaBCWaSSl0aJ6pSVCimZRCh+aZmgQlmkkp9IRkk5gkk6BEMymFnpBsEpNkEpRoJqXQE5JNYpJMghLNpBR6QrJJTJJJUKKZlEJPSDaJSTIJSjSTUugJySYxSSZBiWZSCj0h2SQmySQo0UxKoSckm8QkmQQlmkkp9IRkk5gkk6BEMymFDs0zNQlKNJNS6NA8U5OgRDMphQ7NMzUJSjSTUujQPFOToEQzKYUOzTM1CUo0k1Lo0DxTk6BEMymFDs0zNQlKNJNS6AnJJjFJJkGJZlIKPaG7O+kkojvRJCbRTEqhJ3B3ofZ64Eg0CUoyc1DoS52nUjwJ43xeiiZhiGYmCn2ZsyAe/yGeBHAawpf/SybVdUTT0ExDoS9yHsGXfwsnlZ0F8OyfoklVopmPQl/iIn6XH8kmtZyn7yqZokkld6KZkUKf7yp8Vx8KJ1VcRu8yiKJJJSOiWXI5rVHos10PRWOTEIZ+1RRNKhkcmhp9EYU+16jcmZsU1xG6jhRKJsWNiqahuYBCn2lk6ISTwroi1xVCyaSwkdE0NOdT6POMj5xsUlJnMjtDaGxS1JRoZl9MoxT6LFNmoXBS0IQBqdEpaVI0M6+lVQp9jkmT0NiknEnzUTQpZ0o0JXMmhT7DxLTJJqX0RLMvgqJJKdOiqdHnUegzTM2abFJI73ic9vWQ2sRoavRZFPp0k6ejbFLG5FviokkZolmEQp+sP2huB1FVbzT7AyialCCaZSj0yeYkUDYpYM5vlKJJAaJZhkKfbF6hyya5zfqFUjLJTzQLUehTzQugbJLbjd8ab8VPNMlNNEtR6FPNbG3ZJDPJJCjRLEWhTyWbxCSZBCWapSj0qebery6c5CWZBCWapSj0iWb/QimbZCWZBCWaxSj0iWZHTDbJytQkKNEsRqFPpNCJaf6DkaJJVgq9GIU+zfyEySZZKXRimt/ZkjmVQp9GoROUQicmhV6OQp/mOWFjo/b8lgqySVa3otkZPtGkiJd8TY2mZE6l0Kd5DtpJ1O6u3Z+fePKdkMVLO4smocyPpmROpdAn2kesM363ovn4TeUXy4YcJ+D0aPpDA+S1IJrF17pyCn2iG/G7FU1Dk8weq1k0CWd+NMuvdeUU+kSdU7A/mffdn4XUBvMnmtQhmsUo9EmG83fzpNLLZTtEk6BEsxyFPkFv/i6zOeoUSGZO/kSTAkSzJIU+2t3oAN76LuEkOdEkKNEsS6GPdBWxu/6Tb31f0UWzBbejOTKzokl6olmaQh9tdKHf+q6SC2YrRJOgRLMshT5egmiWXC7bIZoEJZpFKfQJbsVsVDQLrpVNGTc1b3xPwbWyKaJZkkKfYlQ2+7+l4ErZmFG/a/Z/S7mFsjXTo6nPZ1Pok4zJZu93lFsm2zM5maJJGUuGpmhOo9AnGsxm79cXWyKb1D8ERZOqpkZTn8+m0Kcaymbfl5daH1s1MZmiSSlzh6ZoTqXQJ5uXzVKrY7tmFnqh1bFhhmYhCn26m9ns+eJCS2Pbblb3yC+GDKZEUzJnU+gz3Mpm99eWWRebNyGZoklJhmYJCn2W3hiO+0rIpL+7R34p5DE+mpI5m0Kfpy+b474QchmdTNGkLEMzP4U+04RsllgOHE0p9ALLgSeGZnYKfa7OETnuyyCjkckUTUozNHNT6IN2edT+sVg/0SQo0azDDg3IFEzRZCnRJCjRrMUODciUIdFkKdEkKNGsxQ4NEE2CEk2CEs1a7NAA0SQo0SQo0azFDg0QTYISTYISzVrs0ADRJCjRJCjRrMUODRBNghJNghLNWuzQANEkKNEkKNGsxQ4NEE2CEk2CEs1a7NAA0SQo0SQo0azFDg0QTYISTYISzVrs0ADRJCjRJCjRrMUODRBNghJNghLNWuzQANEkKNEkKNGsxQ4NEE2CEk2CEs1a7NAA0SQo0SQo0azFDg0QTYISTYISzVrs0ADRJCjRJCjRrMUODRBNghJNghLNWuzQANEkKNEkKNGsxQ4NEE2CEk2CEs1a7NAA0SQo0SQo0azFDg0QTYISTYISzVrs0ADRJCjRJCjRrMUODRBNghJNghLNWuzQANEkKNEkKNGsxQ4NEE2CEk2CEs1a7NAA0SQo0SQo0azFDg0QTYISTYISzVrs0ADRJCjRJCjRrMUODRBNghJNghLNWuzQANEkKNEkKNGsxQ4NEE2CEk2CEs1a7NAA0SQo0SQo0azFDg0QTYISTYISzVrs0ADRJCjRJCjRrMUODRBNghJNghLNWuzQANEkKNEkKNGsxQ4N6M7Q+93R6/v7t7/+/vjZv/zmq4f//u2b3e7XPxw/9fb1/dW/+s8WxuvM0Lhk/uWXu93PrjPaf7YwwYJo/vkhml/8eDxRNKeyQwNGFPrus3eHT358s3vI5k9f7z9//NT73evn71DoJDU8NfuS+eHwFa/+5fgdpiZpzY/m4xddjc8bZ8spOzSgp9CPidt7++qXXz1+8vM3X+1D+I8/fvrXfUrvP/1xd0zky79uni2M1z01RyTz03evvr9/+Nc+kVfJFE0Wmx3Nn77++Q/7TH57L5qz2KEBZxn69IeH2zW/v7/I5mf/4+f7u4g+fffbN/thuf/g8N+fvn71X78+JPLlX51nCzOcZmhSMj++Ofy6eZ7RzrOFOWZH8/HUQ0BFcw47NOAsmt8d7g/69jKb//YP+zsvP/7i397sf8V8/fjJd/c//fcfjx+9/KvrbGGOkwxNTObxe153JVM0WWxZND+93T8aJJpz2KEBpxn6+ObLHx/+8/rl4aB98N5+9n+/29/ieft6/4vl462f+/ePD1C+JFKhk9hJhqYnc/+V3x7+b2qS2pJoPvwG8Op/Pn6vaE5mhwacF/rnv/33w7/Os/nu/eHOy28VOgWdTc2pybz/89Pjk6YmqS2J5k//+ZdPz9cUzcns0ICzDL3d5/GLHy7vPXr34SGAHz57p9Ap6DRDU5P56Y+7pwcsTU1SWxLNB3/7+jGcojmZHRpwnqG/fPP4moqLbP709Vf7l0x+PDwc9NXxk/v/KXSyOcvQtGR++m731dNXmZqktiCaB1e3hzrOli52aMBVhv7633bfXmZz/xyPN98esnn+hE2FTjaXGRqfzJ++OTzt+JGpSWqzo3l4sF2hz2eHBpxm6MPuH3+8//SvD2G7zOaHV//08N/DPUdv9y+p/OPxBpBCJ5uTDE1M5tun+zb3TE1mu3vQ8enZ0fz03e73++d3uMt9Jjs0oONlaw9he37To8Mvmu/273T0+vnlkydvdaTQyeb6tUEjk/nxzfOX3JuaLHD35PzTs6N5/+HN0/Pm7kVzBjs04PqNZb788f4qmw+/Yn57zObhbYmf3idboZPN1bt3jE3mh5cvuTc1WeDuzPOnZ0fz4eOTP4UhmpPZoQH+bhBBiSa13V3bf1o0a7FDA0SToEST6joa/YFo1mKHBogmQYkm1Sn0WOzQANEkKNGkuq46F8167NCAYtHsfroo9DE1qa77QXTRrMUODcgeza7nlMAwU5PqOp8TJ5rV2KEB2aLZ/eCTPmcsU5Oabswv0azFDg3IF02FziKmJpX03Bp5nl6iWYsdGpAxmgqdJUxNyrucVZ3DSzRrsUMDckZTn7OAqUlRnXOqc3aJZi12aEDeaCp0ZjM1KaV/RHV+XjRrsUMDMkdToTOXqUkBQ9Op6yTRrMUODcgdTXe7M5OpSV6jhlLXyaJZix0aUPx16AqdcUxNshk/j7q+QjRrsUMDCkRTlzOHqUkOE+dR11eJZi12aECJaOpzZjA1SSzVbQvRrMUODSgSzc6DSMVzk6lJOknvJxTNWuzQgDLR7C10pU4fU5Mk0j/mJ5q12KEBpaLZfTQpdHqZmiyV6fk7olmLHRpQ8s+nZrkkWmVqskDO5+KKZi12aEC5aA4dV26sc8bUZJ7sr6sRzVrs0IA40fSAOmfiRJPVKPMaWdGsxQ4NCBVNnc6LUNEkvILvdyGatdihAcGiqdB5EiyaxFWwyw9EsxY7NEA0CUo0GXRXussPRLMWOzQgbjTdWN+4uNEkgjpdfiCatdihAXGj6QH1jYsbTSqrV+WPRLMWOzQgdDR1+paFjiaV1O7yA9GsxQ4NCB5Nhb5dwaNJaSG6/EA0a7FDA0SToESTJ3G6/EA0a7FDA9YTzTBHM2WsJ5pkFKzLD0SzFjs0YD3RjHdYk9V6okkeEbv8QDRrsUMD1hXNgMc2uawrmiQVtssPRLMWOzRANAlKNLcpdpcfiGYtdmiAaBKUaG7OCrr8QDRrsUMDdrlkX3n8w55F1htNpltLlx+IZi12aMB6o7mi45851htNJllVlx+IZi12qGlrGgLM4/pt2Pq6nKoUOqyYSd8qXc50Ch1Wy7hvki5nJoW+GeZDa4z89uhyllDom2FQtMXV2RhdzmIKfVNMi1YY/i3R5aSh0GF9FEArdDkJKfTNMkJW604LtMC1SGoKfbNMkpW6u1Poa+cKJAuFvmUmyvrc3Sn0VXPdkY9C3zZjZV0u69yVtyauNzJT6LAWV3WuGNbCVUYJCp0jw2YFFPr6uLYoRqFzZOqsgT5fE9cUZSl0Thg94Sn0dXAlUYFCh1VR6NG5fqhFocPKKIywXDVUpdDpYSpFpTQi0uXUp9DpYTwFpTmicY0QhELnBjMqnsM1oj6C0OVEotBhVY7NoUJq0+WEo9BhTZ7bQ4/Uo8uJSaEzkvEVwcl14NqoQZcTmEJnJHMsANtfz50uJzqFzgSGWV12vw5dzjoodFgLdVKeKmdFFDozGXHF2fCidDlro9CZyaQrzW4Xo8tZJYXOfCZeSba6CF3Oeil0ljD2irHT2elyVk6hwxoomax0OS1Q6CRiFuZkc7PR5TRDoZOIkZiRnc1Cl9MWhU46RmMudjU1XU6DFDopmY9Z2NSUdDmtUugQneZJRZfTNIVOJqZmKvYxBV1O+xQ6mRifidjCpXQ5G6HQycgMXc4OLqHL2RKFDqFpopl0OZuj0CEybTSDLmebFDqFGK9z2LOJdDkbptApxJydwXZNoMvZOoVOQYbtNHZrJF0O9wod4lJPI+hyeKLQIYfdtaln0UpFJdiKbroczih0Kml4Dnc02Jwma2F7Em3FFV0O1xQ6lTQ6kPv7amqVrX1nbvy8i0pdl0MPhU5FbU3lEY09odRXvTNpt+KZLodbFDokMb6eRn3hmjtr6k6MmUK6HAYpdIJY96ieegfy0NeveDNSb4Uuh5EUOkGsd2LPezz45netdCeSb4UuhwkUOnGscnLPf3rXje9c3S4cJN0KXQ5TKXQiWd34nv1c7Zvfv7JNeJRuK3Q5zKLQYb6FHdZzFqssskRbocthNoVOUCuY6Qk6rOts4v/g1xJuxRp/fAhBoRNU/JtpiUrs8oy6f+pZW3HXbfrZDH1Fpq0ApnDwEFfoTk9aPSdn1tfnY/ehp8SXdPvQ16XeimTnBdvi2CGyuIWe+Kbk8zPCevv89j5M6evJ1X775KVPhus6v4RnB9vhyIEZ0pfOsce6qrO/cpfeoT7q+2+fb/r+1egwjwOHlZhcVhnlqZz9md7o88tT5td4lxvndvMicu2EyQSTOWxYiWTVtVyuvjk8xfvqs10/eMbNuD7rWxeWbyeMJpjKUcOKxCj0fGXT/SYzJ32a9EZ5v/NLuHGJZbcCuMlBA9PkrJqr877rkW0FA5c8sNyENDpM5ZiBSfIWTf8bmld4vGGo0YtuBTDEIcNKVbr7PXfNXL7HTLU2H15E0a0ABjliWKk6NZe/ZE4uoe7t86FFFN0KYJgDhhUr3nIlKqbjb46FKvTjMkpuBTCG4wVGK1MwT+8wE7bQ7+7LbgUwisMFxipVL4/vMBO40O+KbgUwjqOFRuRvvHLlcvZ3wes2evc6im5FoUuC1XOw0IjspVeyWvoeRy+2gGedC6ixFcAQxwoNyVl6ZYvl4sKqF/rZ56puBdDHsQKjFO6VoDV2vMO96GUG3QoIx6FCoxLfoC3dKvHuaT55AL3sBcfbCojJkUKj0t5HXb5UIrXY2YPo294KCMyRQrsSdnqFTolRY9fPyNvsVkB0DhRalqrQazRK9Rbrfnb9JrcCVsGBAsOqNErFGrvxSrmtbQWsh+OEjVhy93udPqnzZLCBV73X2ooalwor4zhhI5a8OUulPil9sSPewabWM841OgxzmLAhMwu9WpuUu+Cx70ZXaysUOgxzmMCQioVe4JLHdvnjgvKvJ9olw2o4SmBAxS7JfNFTuvxxOQod4nKUsFFTaizzUmpc9tQuz7ua4JcN6+AgYaNG91nVJslx4bO6PNdi1nHhsAoOEjYsfqEnvvTZXZ5hLeu6dFgBxwjcVLlHkl38si5PupRVXjzE5xghg5b+PlbtHyXB5S/v8lQrWaT25afT0vFBJHJFBmscWD19V/0nWbaARF2eYCXL1b78dNZ4fLAGckV6D+NqfROrp/iq/yCzF5Cyy5etJJXqC0hklccHayBWpLfagXXdfvV/jjkrSN7lcxeSVv0VpLHa44PoxIrkDsOqkYkV4MeYtoQsXT5jHVkEWEICLR0fxCJVJHccWCvP1mMlBvgpRi8hX5dPWkZGEdawXBvHBxEJFakdJ9XaB9ZjM0b4KUasIW+Xj11FdhHWsFgjxwcRCRWpPU2q9U+sGH0+sJEFunx4EYWEWMRS7RwfhCNTJPY8p1oYWDF+hp5V3BXq8ltrKCzGKhZp6vggGJkirZPHBtc/sYL8BNfLKNrlPWuoIcYqlmjq+CAakSKtkym1/oEV5Cc4W0bxKu9YQz1BljFfU8cH0YgUSZ0NqbVPrCjrf1pHpS4/XUJtUdYxV1PHB+FIFEldDKx156vM8t/vdl8NLqRilx9XMPMbP333kIJvAywkhqaOD8IRKFK6mFArH1hFlv/xzfhCL7Cc3hXM/EaFfqqt44NwBIqULifUuidWidX/9PVuVKHnX8nACmZ+o0I/1dbxQTjyREJX82nVA6vE4g99N6LQ868k0wIU+om2jg/ikSfS6XhMcM0Tq8DaH/t8sNCrb6NCT6Gx44N4xIl0OqbTmp/3k3/pf/tmp9BLraS+xo4P4pEmkumcTSseWNmX/uc3O4VebCXVtXZ8EI80kUz3bFrDxOp+AnnmlT/dPFfoy1dS8wUAo633+GAthIlUeibTGgZW92vCBlf+9z/9al/Hv/7dj9en/fU3Dze/P//yP44f/eHho1df/PBy+qc/Hqr81f/73QoKffTFf/rL/sfeff7F98+fORb6pz//6nDCD9ffc9jFz397fcrYpdR9Rd9YKz4+WAthIpW+ybSCidX9ni0DCz9W8sGXz5W+f1n566cnuz0U9u/3X/mH6697/Iovf/zUUKGf7sjhB79/LvTnRxdetmB/ymfvTk75ouP3ouG11Hy7nUlWfHywFrJEIr1zaQUDq/tt2G4v/OOb3Ymf/XDy6deHF5cfffvS7rt91x/tP/mz74+F10ahn+/I7svDJx8L/f3J539+7O3HQu86ZcJa6r5/3hRrPj5YC1kikf65FH9inf7xspdquLnui/ba39Z8/vx/+u7shLcnH736l+P3f/ru1e9/vG+p0C935PGnOvx8/8/154+F/r/PTnl94+w71lL+b84tsObjg7UQJdI4m0off/Hu7KToMbu766j0m6t+vA3+s+9/3D9u/M3Jzctjrb3aP67+18MJvzp+9Phlz531/z3+r5lCf7wf4tXv/uN5Rw6/vDzdPXHYqscNOf7u03/KuLV0XWdxrfr4YC0kiSTOhtKHi8kcfmDdXbkfWPX+nuKnh4mPrz97bOXHQv/s8R74413vx48ODXZ5t3Izhf7+7E7z90+/vBxr++mR88O9FY9Pej9/U51PJ6eMWEvXFRbZuo8P1kKSSOJ0Jr199c+/eHdx6nVlRndzzB6a+qR9PjyX2aHQn+9Yf392N/uHjhuhrRT6xW8rhw/3P+tjbT/fL3Hy1vVdp4y4z32/ltrZmG7o+Bj+uWGYIJHCxUT62ECh392asu8vyufl1daHQn8+6cNZZ+1Pe2730+9soNA/7M5/tg//8MX3z88RODnh7fOG9J8ysJbawZhh8PgY/rlhmCCRwsDAij6xumbwzTW/vbx7+P1TLX98c1rQh4+ev3B/I7TVQn/f8XDC3uXjDO/PC73zlMG1dF1doa38+GAt5IgELudRx8AKnbTOfrix5Otm/vDURrcqvOFC7/0xDiec9PRL8fefMmIt6yr0tR8frIUYkcDgwKrdSAO626F/zVev0No9PyPs/G71bRV611PaLn++i0LvPGXUWpoq9NpXMI0QI5a7mkbXAyv2xOruhqmFfni+2/6klye+babQu360g2yF3vfuAQGt/vhgLaSIxa7vL1zbwOouhv4lf+jqc4XeW+gnN90vCr3zlNFrWUehr//4YC2kiMXGzaLIE6u7FhT6+IsvVug9b+Ueu9DTfRXcIkQsNXISRR5Y3aVw+y73nnc1a7LQhy+/WqE/XXlD31dPA8cHayFELDV2EgWeWN2VcLvQO+tr04Xe/6S4rIUe/c+nNnB8sBYyxLjphNgAACAASURBVEKj51Dgl+Z0F0L/envra7OFfv1jvP317/79vkyh76/Aoe+rpoXjg7UQIRYaP4bWNrD613v5Eur7+w+f/5f/8/zWr8kLvfrODS/gso6ffq4yhR5Yu8cH8YgQy0yZQmubWP3rPfxtlpNqfmn4Ngt9eAWXb/369AY7Wy/0lo8PwpEglml5YA28EP3ibUtf3st9i4V+eBSi74+zKPTkXwsdJIhFOl+/dUPt9U5yY7mHP/b5XD9/fn7V2mYL/fgHU4878umPu+OPtfFCb/r4IBwBYpGmB9bAu7k/tPPv/uPh33/9zeFHe+ymzRb6419DPezIp7988/wbjkJv9/ggHAGCPrfm64fLd389PkcuR6EHmPMjlnD5frivDmWduNADbAWE5fCAXhMa/cvjpxst9DFr+Ns3132u0KEchwf0ulkff/vDSXv9/umzGy704yPnj372w/FzCh1KcXhAr4H6+PuffrO/mf75F9+/fG7Lhf7w0/yvw4786rc/PH9GoUMpDg/oFaM+QqwixCKCrAKCcnxAvxAFEmIRMVYRYhEQleMD+oUokBCLiLGKEIuAqBwf0C9EgYRYRIxVhFgEROX4gH4RCiTCGu5jLCPCGiAuBwgc3HX+UfQAFRJgCQcB1hFgCRCYAwQO7k68fDZAhQRYwkH9dVyt4Pr6gi2rfoxCDHdXDp8OWGOV1F/H8wo6rynYvOrHKARx3eh71Wus+gKeVF/Ibtd9FSl0eFT7GIUoerqido/VvvwXtVfycPn6HG4IMyygsp6uqFxjtVv0RISdUOjQL860gLr6mqJujwUq9BA7odChV6BpAXX1FEXVGovU50F2QqFDj0jjAqrq64maPRaq0IPshD6HbqHGBdRy62ZfxRqL1edRdqLrbne9DgodBh+XrddjwQo9zE6odOgQbF5AaSdl0NcN1WosWp8/LKjSii4v9/qq0ukQbWBASV2d0FELlWqsWn32i1Lo91eFfvxU2WVBKOEGBhRz2d69d91WK/QqF3tTnTV1XWrXtaXS2bSAEwOKuO7u/odiq9RYxD6vdK9B54V2XV0anS2LODKggK7R31sHNWos4B3uezVW1XOZnb9+qXS2K+TIgOw6x35/F1Qp9OIXOUr5dfX/atN1hXkonc0KOjMgq56Zf6MIitdY1D6vUui9J/VcjRqdTYo6NCCjGRO/+B3gYQu9+MpmXJ5GZ5PCDg3IZta4L9zocfu8/E7MuDiNzhbFnRqQycxhX7TGgj4j7lHZxc27MIXOBgWeGpDF7BtvBWssdJ+XXd7ci9LobE/osQHpzb8ztlyNBe/zVWyFO93ZnuBzAxJbMudL1Vj4Pl/FVmh0Nif84ICkFk35MjW2gj5fxVZodLZmBZMD0lk440vU2Cr6fBVbodDZmFWMDkhl6YzPX2Mr6fMSzxFcvBUanW1ZyeyAJJZP+Ox9u5Y+z7/S5Vut0NmW1QwPSCDBhM/c6Ovp8/w7sfzsNTqbsp7pAYslme85e2y3mjvc93KuNs15K3Q2ZUXTA5ZKM9+z9dhuXX2ec8GpzlijsyWrGh+wSKrpnqnG1lbne/m2Is0ZKXS2ZHUDBGZLN91z9NjjWa6pgQ5rzbMTyc5zTfsJCyl0NiPlbE/f6MczXFMBPa41x06kO8c17ScspNDZjLSzPW2PvZTYehroaaVpf7lJ/avSevYTllLobEXqyZ6weU6fXLaaNyx9WWjK58Ylv+tjLdsJyyl0tiL5ZE/WPedntJJGP1tmyq1Icj4v1rGbkIJCZysyTPYkPXZ1JuuooItV5tmKBNaxm5CCQmcrckz2BA3UcRZr6KCrNebZiuXWsJmQhkJnK/JM9t2SB5B7vnkNHdSxxhxbkcAadhOSUOhsRK65vptdRfO/M6iYW6HQ2YyGpgncknOuz2mjxsr8SbytUOhsRoMTBbpknet3025iNnfb/NSsrch45Sh0NqPRmQKXcs71/XmP77Gm63xv9A+4e/7K3NcObEHDUwVOZRzrzy/J3u12t8ps4OSmTNyKnC++V+hsxQYmC9znvgn4fOa7MfKtJJJJO6HQYbmNzBY2L+8N9K4XZS9u8phFNHVV47aiYw+TibmPkJ5CZxty9kWmMgr5HrB5FnWXbRPvFTrbodDZhsyFvpVGz/eTKnRYSqGzDRnrIl8ZxauibD9oxkaPt4uQh0JnG/K1xZa6aJW7GG0TIReFzjbkvWmZsejynPE8OX9OhQ5LKXS2YZ2FHqvRs/6YOZ+KkONcIR6FzjbkfDLXVl5zlb/PMz2FPsOZQkAKnW3I+GqrvI2+BXn30XXDVih0tkGhB6bQIQWFzjbkaQqFnkTejXTdsBUKnW3IUhQKPY28O+m6YSsUOtug0ANT6JCCQmcjko/1O4WeyF3erXTdsBUKnY1IPdYvWyhva5ycfal+KneRebdSn7MZCp2NSF4ThQv97upfmZW7SIUOSSh0NmLlT3N/Ov9y9+6/XFL+ny3nNip0NkOhsxG53/s1d20cLqDg4/Uvl1TgR8v5cyl0NkOhsxU53yi8SKHfZf7TbleX93hZRX60jL85KHQ2Q6GzFWuvi2L37le5uMeLXM+5QkAKnc1Y+9uKzqjY3ZWMF7aYQodFFDqbse5Cn/rMsesun9Tq5Z7ud3qZazlTCEmhsx1rfgr13ZRC76/u0aU+6fJSWfevXFCbQmc7VvyuonejC3ZEY48p9fEXmNCaf+OC+hQ6G7LadxW9u9T3haPvUx/4wtEXmNaKf+WC+hQ6G7LSQr9q176LnfS0t5tfPvYSE1vpFQQxKHS2ZK3vKjpcr1OfxT7wXa3cQlfobIlCZ0vWWuhDf5FsXp2ffOekS8tovVcQ1KfQ2ZS0E75oX9yo2HldfuP7K9V5+utHobMlCp1NSTrhS9dFX8kurPP760avVOf3afdUn7MxCp1tSVsY6c5r7CVe1+zSm+dd51Krztd+/UBVCp1tSdhRNfriumnT9Pn5+VSr86Sbqs/ZGoXOxqy70E/+CtpBqjo/P696fZ5wV93hzuYodLYm1Zyv1hcvZTvzme19ns+uXp2nvHr0OVuj0NmaVJO+YmEc+zZtne89nmPFOr9Ptq/6nO1R6GxOmraqWxj7nyF5ne/tz7TujdsWrh6oQqGzPSlugFa/R/cuS58fGr32T5Zga6tfPVCBQmeDljd6/cLI1OcZz3i0FNdO7asHKqh96EIVCyd+9cJI//B5mfMeZ/m1o8/ZIoXONi2a+dULI2/nrrzRq187UIlCZ6MWjP3qjZG9cFfc6G6es10Kna2aO/jrN0aBuo3Q6LN2uf61A9UodDZr3uyv3xhFynaljV79yoGKFDrbNaMzEtb53LdvKVS11Rt9xl7X/2ULaqp9zEJNExsg2VuoLfjrJ8WKNkajT716si0G4qt9yEJVUzoj4TuiDp5V74kFa7Z+o0++erIuBqKrfsRCXWM7I0md95zD1a313osqWrL1C73w1QPrFuCIhbpGdEGaPz/Wex5X97/3fmXZjo3Q6KP2Xp3DvUKH+45C7To5yYUMnD70pYUbNkShD+3/7GcjQGtiHLBQWV8rzH/yWtcZDX7J2aV2fEnphg3S6CfPIrzr/nSlZUEoUY5XqO6uV5ozn7yQqxOK92uA58U9yXrtQBPCHK5QX5C26LvwCvUap9CPAlw9EFW0wxU2r7euarRruEYH+jhaIZbeG6BVujXQne7AbQ5WyGn6vcJ9dylXqlaFDmvhYIWMpj/M2/sgca1m1eiwEo5VyGfG07b6Cr1aryp0WAnHKmSzvM9fzqBer2p0WAeHKuQy52VVfS+cq9iqCh3WwaEKuSTp8+OZ1GxVjQ6r4EiFOLr6/FDoVTtVocMqOFIhmo5Gr9upGh3WwIEKMZ02euVGVeiwBg5UiOyx0Ws3au3LD8Wb5xGVZEJ41Ruk+gIiUehEJZkQXv0Gqb+CMB62wm4Qk2BCdAH6I8ASolDohCWYkFrqP9MdoT8irCGEw0bYDUKSS0hNobdrdyx020FAYgmpKfR2HffBdhCRWEJiLfZ5jEXU97wN9oOApBISa7LQg6yiNoVOZFIJiSn0Zp1sgv0gHqGExBR6sxQ6oQklpNVmn0dZRlVne2BDCEcmIba8xfHpL//0y92DX/3uP6quYw12F4W++Q0hGpGE2HL2xqc/7l588UO1dazDxQ7YEKIRSYgtY2/87ZvdqVf/Umkd63C1AZvfEaKRSAgtY2v89PVuN77RN19fCp3oJBJCy9gabx/vaf/3h3/+/U9v9v/++Y91VrIGHT/+xneEcAQSQstXGh/3Hf7Z0wPnn77bN/pXVVayBl3PgfO8OGKRR0go9WvWctbo2/M72Q93wN+6ib7t9ur86be9JYQjj5DQigr9cJP89Bb5h/0N9ndTV5L+Jw6p52rQ6EQijpBQ8nobbIy//+lX+/vKf/27jtvWf/3Nm93u8y+PrzD/6x8ePnr1/OK0wy3yb0++ev+JW0+L61jK3d7AAtug0FkBcYSEShf66QvJv3yu9P2j46+Pj4rv71f//f4r/3D5dZ/+8od/OO3vq4YfWsrd3WYKvfdq0OgEIo2QUOFCPzyv7dnPfjj59OvTF6V9+9Luu33Xd5p2C/3u2aSfZ6UUOmsgjZBQ2UI/7/Pd8yPg+8//p+/OTng7/HLz/XeNfQz97m5ThX7jWtDoxCGMkFDRQn+8Df6z73/c333+zcnryI9F/2r/uPpfDyf86vjR45d130R/O/ZZ7nfnZv5kK3L+8rSPv3jXexrUJIuQUNFCf//0+PjBn988P2v9sdCPLzE/3vV+/Ohw13tnbX98+f6bS7m7NOXHWaezK+HDxd0YCp0wZBESKlnol09i+/Bc1Ydufr5j/f3Z3ex9L047NP2te9wPS7lq89NGb/Xjs+vg7at//sX5Lml0ohBFiOxGW7y/uPP8UMmHgj8U+vNJH87uZd+f1vUg+uFB9ls30B+W0lnnLw3Y6scX18FHhU5QogiR3WiLt5evMnv/VMnn954fPnr+wp7nsr+/8fT3k6XcqPNmXV4Fl4Wu0YlCEiGy/rK4buYPT518q8K7C/39bugO96elbK7Qr5711lHo5ighCCJE1t8Vl69Ze3R4EP38bvURhf7Hk6fNDS5lc4V+8YmrQncTnSAEESKbWuiHW9nnrygfLPRPb8f0+elSNlTo11fAdaFrdGKQQ4isvyo+dPX5nEJ/fBO5wT4/X4pCv/1FUIEcQmT5C/3xlv7Pbj9+3rGUbRT6yKrW6EQghpBQwdeh33in1imFfng/mpvvENe/FIU+8csgKzGElFL32+1CH/Wu7DcL/fD09pM/1DZxKa0X+uii1ugEIIWQUrlCv/HXTscX+mOf33w/mYGlNF3o41+Q5qVrBCCEkFK5Qj88l+3srWA+fP5f/s/zW7+OKvTHd4W98TfQxy2lWRN+5A3uDuEIIaRU8EH0w99mObnP/aXhxxb64Xl1t/4E+siVtGrST7y97SEcGYSUCj8r7vTZbIeb28/v5T6i0A9n8LPBl6sNr6RVCp11kUFIqtx97o9/T+W50f/8/Kq1kYU+/PfVRq+kTZ2vC7yl9oLZOhGEpAoW+uNfOn/1u/94+Pdff7N7voE+stAv77JfsJI2KXRWRgQhqYKFfv/h8t1fj8+RG1Xoj28Qd6n/CXL6CoJzjEJcHX+N+8xFo395/PSoQu9+p7lbhd7yC9SgAQod4hoq9Pu//eGli1/9/umzowr9/fRCb/+N4WDNFDrENnBX99//9Jv9zfTPv/j+5XOjCv3tzEJX6hCUQodYLhszyGPXV38Nve5ygCsxZgWw19mWMRr9dBVKHSIKMSqAg86WDFHoV4tQ6hBNhFEBbSn5yrVSOteg1CGSAJMCGjOt4IYbMUCh9y9BqUMU9ScFtGZ8u41sw/qNfnsFnv4OEVQfFNCe0c02sgSjF/qeUofaqg8KaFDiWltDoR8odaio+qCAFt2otBmFV73QpyxAqUMltQcFtKm7z6aX3eOX1270qZev1KEChQ453Cj00efwUouVC33WxSt1KEyhQzR3F+5r3+k++9KVOhSk0CGvmbfKz581XrXQl124p79DIQod8pncZX2FXrXRl1+2UocCFDrkM73Devq8ZqGnumilDnkpdMhnenn19HnNRk95yUod8lHokNZpX81orp4+r1foyS9YqUMeCh3Sueqq6bXVV+jVGj3L5Sp1SE+hQzrXHTW9tHr6vFah57tYz5SDtBQ6ZDW5sXr6vFaj571UpQ7pKHRYZrCOprVVb58/VGuFw7XEZSp1SEKhw3zJq6jvAfSDCoVe7JcIpQ6LKXSYL20FPTVab7eVb/Sil6jUYRGFDlE8d1lfrRW/0738bxBKHWZT6DDesroZ/X29F1G40as8aq/UYSaFDuMtLvSR39n7hUUrtlKfH3j6O0ym0KGczo7qqKz+HitYsjX7/ECpwyQKHW7L8MS30393n3v/BRar2ep9/kipw1ghDlkIKm+bzDvzQkUbpM8PlDqMEeeYhXhCtkiRqo3U5wdKHYYEO2iBQQXKNlyfHyh1uCXiUQs1raAxsrdtzD4/UOrQJ+xhCxWspS1y923cPj/w9HfoEvu4hbLWUhKZb0EH7/MDpQ6XVnDgApdyNvou8B3uF5Q6nFjLgQu5rLMQ8rXuivr8QKnD0aqOXEhsxWWQq3dXVuePVnw9QjorPHYhmVWXQI5KX9vN8xNKnc1b68ELpG/fFff5gVJn01Z99MIMLQ38tAW89jp/5OnvbFYDxy+M1tys36Ur4YRnVZ1SZ5NaOYBhjAZnfKoabqjOj5Q6W9PYIQzbk6KK26vzR0qdLWnyIIYT7c/z5W3cap8fKHW2ot2jGLYzy3cLHgBf8r2rsZUgsG2tH8ds22Zm+G5uLc/+xvVR6rRuEwcybMGMZt5MmT/x9HdatqmDmU3Y8LiedHN7Q7fNzyl1WrXBw5mGbX5Uj27pzdb50eaTQou2e0DTIiP6/rmr+9p64OQNUeo0xkENzdmNUHuNQSh1GuKwZu2M4x6qfCSlTiMc3KyZUTyK/RkkSTRAobNmRvAo9mgUT39n5RQ6a2PiTma/RlPqrJhCZ01M21ns1zRixjopdNbElJ3Fnk2n1FkfhQ7N00rzKHXWRaETnYm6mP2bT6mzHgqdyEzTJOzfMmLIOih0IjNFk7CHy3n6O/EpdGieEkpDqRObQicaAzM5+5mQUicshU4khmUW9jMxOSUkhU4khmQW9jQDpU44Ch2ap3QyUeqEotCpzUDMzv5mpNQJQ6FTk2FYhP3NzNPfCUGhU5MZWIQ9LkCpU51Ch+bpmFKUOjUpdEoz74qz3yUpdWpR6JRk1lVhv0sTdGpQ6JRkxlVhz2tQ6pSm0KF5OqUWpU5JCp3czLPq7H9Nnv5OKQqdnIyyqu6u1V7SRrkCKEGhk5MRVpdCj8SVQGYKHdql0KNxRZCRQic14yoQfR6Qa4NMFDopGVXBKPSgXCNkoNBJyYgKRp8H5mohMYUOLVPosbluSEihs4RpFJ0+j88VRCIKnSVMovAU+jq4klhOoUPTFPp6uKJYRqEzlYmzKvp8XVxbzKfQmcK0WR+FvjquMeZR6ExhyqyPdlglVxvTKXRonGZYK3euMI1CZ4iBsnI6Yc2UOuMpdG4xTBrgKlw9xyGjKHRuMURaoAtaoNQZpNChdWqgFUqdmxQ6lwyM5rhGG6LU6aXQOWVYNMkV2hjPlKOTQueUGdEkV2qDlDpXFDq0z8xvlFLnlEIftMuj9o/1wjxYq+ajyRgRS10067BDAzIFM0o0I84Cxmk8mkwR60AWzVrs0IBMGYoSzTgzgKkajyZTxSl10azFDg0QTYISTa7EKHXRrMUODWgwmvWPd1JoMJqkUP/p76JZix0a0Fg0qx/qJNNYNEmpbqmLZi12aEBj0VTm7WgsmiRXrdRFsxY7NEA0CUo0GVal1EWzFjs0oIFoulXepgaiSRHFS100a7FDA1YeTY+Zt2vl0aSoopNANGuxQwNWHk1l3q6VR5PiipW6aNZihwaIJkGJJtMVefq7aNZihwasMJpulW/DCqNJCNlLXTRrsUMDVhZNj5lvx8qiSSw5R4Vo1mKHBqwsmsp8O1YWTeLJVeqiWYsdGrCCaCrxbVpBNIkvR6mLZi12aEDwaLqLfbuCR5P1SD1GRLMWOzQgeDSV+XYFjybrkrLURbMWOzRANAlKNEks1dPfRbMWOzQgYDTdKmcvYDRZvxSlLpq12KEBwaLpMXOeBIsmDVk4Z0SzFjs0oGA0xxw9ypwnpiY5jS31ji8QzVrs0IBy0dTUTGJqktuYUu84VTRrsUMDSkXzxlHjVjldTE1KGCr1jtNEsxY7NKBQNPsOGY+Z08fUpJQbc6jrBNGsxQ4NKBLN/sNFmdPH1KSknqe/d31WNGuxQwNKRDPVqz/ZFFOT0jpGVdf0Es1a7NCA/NG8u7s4JFQ7Y5iaVNExri4aXTRrsUMDskfzrluWS6UlpibV3B5bolmLHRqQO5rKnJlMTarqn12iWYsdGpA3mrqc2UxN6uscYaJZix0akDWabp0zn6lJdd0jTDRrsUMDMkbz1oNQMMTUpLruISaatdihAfmi2XkoKHTGMjWprnuKiWYtdmhAtmh2HwkKnbFMTapT6LHYoQGZo6nRmcvUpLae+SWatdihAWXf+lWhM5qpSW09k0s0a7FDA4r+PXSFznimJrX1zCzRrMUODRBNghJNghLNWuzQgO4Mvd8dvb6/f/vr74+f/ctvvnr479++2e1+/cPxU29fP57yy93uZz+cnIFoslRnhsYl8yWPV8kUTRZbEM0/PwTyix8Pp4jmdHZowIhC33327vDJj292D9n86ev954+fer87FPqHw9e++pehs4XxhqdmXzJf8nidTNFksfnRfPyi85DePltO2aEBPYV+jOPe21e//Orxk5+/+WqfyH/88dO/7lN6/+mPh/Def/ru1ff3D597PXS2MF731ByRzJc8diRTNFlsdjR/+vrnP+zn5reiOY8dGnCWoU9/ePiV8ff3F9n87H/8fH8X0afvfvtmPyz3Hxz++9PXr/7r1/s8fnxzqPfDKV1nCzOcZmhSMl/y2JFM0WSx2dF8PHUfS9GcxQ4NOIvmd4d7gb69zOa//cP+fqGPv/i3N/tfMV8/fvLd/U///cfjR8fvdgudhE4yNDGZx+95fX/5r4uzhVmWRfPT2+c72kVzIjs04DRDH998+ePDf16/PBy0D97bz/7vd/tfJt++fvnF8v79YyRPC/39PtRdZwtznGRoejJP83iWTNFksSXRfPgN4NX/fPpu0ZzIDg04L/TPf/vvh3+dZ/Pd+8Md7N/eLPQ/ezSIpM6m5tRknuTxPJmiyWJLovnTf/7l81PhRHMqOzTgLENv93n84ofLe4/efXgI4IfP3t0o9E9/3J0+GCSaLHaaoanJfMnjZTJFk8WWRPPB375+fIBdNCezQwPOM/SXbx5fU3GRzZ++/mr/ivOPh4eDvjp+cv+/p0L/9N3uqxtnC9OdZWhaMl/yeJVM0WSxBdE8OFS7aM5ghwZcZeiv/2337WU298/xePPtIZvnT9g8FvpP3xye5nnrbGGiywyNT+ZLHq+TKZosNjuahwfbHwtdNOewQwNOM/Rh948/3n/614ewXWbzw6t/evjv4Z6jt/uXVP7x+Lvl09M3z94e4fJsYY6TDE1M5kser5Mpmiw2O5oPt8p/v3/o/KHgRXMOOzSg42VrD2F7ftOjwy+a7/bvdPT6+Hrzs3eK++n4OvTnL+46W5jj+rVBI5P5kseOZIomi82O5v2HN8fnzYnmLHZowPUby3z54/1VNh9+xfz26Q1k9m9L/PQWxI+F/mF3lU3RZKmrd+8Ym8yXPHYkUzRZbHY0Hz4+vqu7aM5ihwb4u0EEJZoEJZq12KEBoklQoklQolmLHRogmgQlmgQlmrXYoQGiSVCiSVCiWYsdGiCaBCWaBCWatdihAaJJUKJJUKJZix0aIJoEJZoEJZq12KEBoklQoklQolmLHRogmgQlmgQlmrXYoQGiSVCiSVCiWYsdGiCaBCWaBCWatdihAaJJUKJJUKJZix0aIJoEJZoEJZq12KEBoklQoklQolmLHRogmgQlmgQlmrXYoQGiSVCiSVCiWYsdGiCaBCWaBCWatdihAaJJUKJJUKJZix0aIJoEJZoEJZq12KEBoklQoklQolmLHRogmgQlmgQlmrXYoQGiSVCiSVCiWYsdGiCaBCWaBCWatdihAaJJUKJJUKJZix0aIJoEJZoEJZq12KEBoklQoklQolmLHRogmgQlmgQlmrXYoQGiSVCiSVCiWYsdGiCaBCWaBCWatdihAaJJUKJJUKJZix0aIJoEJZoEJZq12KEBoklQoklQolmLHRogmgQlmgQlmrXYoQGiSVCiSVCiWYsdGiCaBCWaBCWatdihAbtcav9grJ1oEpRo1mKHBogmQYkmQYlmLXZotru5n4KsRsZQNCnN0MxMoc91NzKbwklZI5MpmpRmaOam0Ge66wjd2M9BPqNTKJqUZWhmp9DnuZuQTeGknNHJFE3KMjTzU+iz3HVFri+vwkkx3XkTTaobH03JnE2hz3HXW+jdnxROypiQTNGkpMlDUzRnUOgzdOftRmBlkyJ60iaa1DYlmneiOZdCn64nbjc/K5vkNymZokk5s4amaE6m0Ke660vbQDaFk8ymJVM0KcbQLEShT3TXF7bbiRVOchv6VVM0qWRiNCVzNoU+zV1v1oY+LZxkNTWZokkhS4amaE6i0CfpT9pgZGWTnEb8qima1DA5mneiOZdCn+JGzoaLXjbJZ8yvmrcKXTTJRDQLUugT3IjZqBNkk0xEk6BEsySFPt6tlI2NpmySgWgSlGgWpdBHuxmy3lMuv0s2Se5WxkZmVjTJQTTLUugjXUXsRm3f+r6yq2YDRJOgRLM0hT7e6Gje9Z5SeMVsxNj8jZynkIpoFqXQpxgZzb6TTXHAowAACdtJREFUSi+X7RBNghLNghT6NAuiWXqpbItoEpRoFqPQJ+qK2mUyu067l03yEk1iuhm/26eVX+y6KfSJDvNvcjQfvxHyuRNNYtoHbFY0JXMqhT7NY8Im/O74/JWySU53t6LZGT7RpIjnmE2OpmROpdCneUrYhEK//AdkcBK00VPz1qmQyPxoSuZUCn2a+QmTTXK6ma/b4RNNcpofTcmcSqFPo9AJ6lbATE3qUejlKPRpFDpBKXRiUujlKPRpZJOgFDoxGZrlKPSJ5o5N0SSzGxEzNanI0CxGoU8kmwSl0InJ0CxGoU8kmwSl0Inp1ot8Dc2kFPpUsklQ/RlT6NRkaJai0Keal03RJLt5hS6aZDcrmpI5nUKf6sbdR7JJTf3RVOhUNSuakjmdQp9sTqGLJgWYmgQlmmUo9OmmZ9OfAaSIvpzd+lVTNClgTjRzraVhCn266TNQNCmiL5qmJpWJZhEKfYapjS6ZFDJ1aoomhYhmCQp9jmmN7l5NiunOWv/9naJJIaJZgEKfZVLaJJNiupM5/QFMSGxSNPX5PAp9nglxk0wK6pyEkx+/hOQmFLo+n0mhzzQ2cHeiSVFdgesZpaJJSaN/15TMuRT6TCMjZ2hSWkfkuiepaFLU2N81JXM2hT5XxzzsGqSSSWkjkymaFDZ2aIrmXAp9tuvcdYRVMilvVDJFk+LGDU3RnE2hL3CZvKsPJZMqLqN3PUUlkypEMyuFvsRFOC8+EE1quUjf5QyVTGq5NTRFcymFvsjd2eA8H6GSSUVn0bz6VbPGiuBANPNR6Avd3b3E8+m/5zUPVfQmUzSpqn9oiuZCCn25u061VwWiSVSimYVCT0MoiUkyCUo001PoCYklMUkmQYlmUgodmmdqEpRoJqXQoXmmJkGJZlIKHZpnahKUaCal0KF5piZBiWZSCh2aZ2oSlGgmpdCheaYmQYlmUgodmmdqEpRoJqXQE5JNYpJMghLNpBR6QrJJTJJJUKKZlEJPSDaJSTIJSjSTUugJySYxSSZBiWZSCj0h2SQmySQo0UxKoSckm8QkmQQlmkkp9IRkk5gkk6BEMymFnpBsEpNkEpRoJqXQE5JNYpJMghLNpBQ6NM/UJCjRTEqhQ/NMTYISzaQUOjTP1CQo0UxKoUPzTE2CEs2kFDo0z9QkKNFMSqFD80xNghLNpBQ6NM/UJCjRTEqhJySbxCSZBCWaSSn0hGSTmCSToEQzKYWekGwSk2QSlGgmpdATkk1ikkyCEs2kFHpCsklMkklQopmUQk9INolJMglKNJNS6AnJJjFJJkGJZlIKPSHZJCbJJCjRTEqhJySbxCSZBCWaSSl0aJ6pSVCimZRCh+aZmgQlmkkpdGieqUlQopmUQofmmZoEJZpJKfSEdjvbSUSSSVCimZTNTEg2iUkyCUo0k7KZ6TwkUzgJSDIJSjTTspfpyCYxSSZBiWZa9jKZQy6Fk3Akk6BEMzFbmcrumE07SjCSSUyGZmp2MpVjKGWTYCSToEQzNTuZyHMmhZNYnhIpmcRiaCZnIxORTWKSTIISzeRsZBoniRROAjl5gFIyicTQTM8+piGbxCSZBCWa6dnHJM7yKJyEIZkEJZoZ2MYUdhfZtKsEIZnEZGjmYBdTuAijbBKEZBKUaOZgFxO4yqJwEsNlEiWTGAzNLGxiArJJTJJJUKKZhU1criOJwkkAHQ9MSiYRGJp52MPFup7O4SkeBCCZxGRoZmILF+uMoWxSnWQSlGhmYguX6kmhcFJbdwYlk9oMzVzs4FKySUySSVCimYsdXKg3g8JJXX0JlEzqMjSzsYELySYxSSZBiWY2NnCZGwkUTmrqz59kUpOhmY/9W+T8lRYff/Gu9zQoSjKJydDMyPYtcha/D7vP3vWeCCWdTUbJJA5DMyPbt8RZ+t6++uezXzaFk3pOsyeZxGFo5mT3lrgI30fZJAbJJCjRzMnuLXCZvctsCieVDExNyaQSQzMrmzff1RM4OrJpf6lAMonJ0MzL3s13FbyrbPptkyoGp6ZkUoWhmZe9m+06d9fZFE4qGDE1JZMKDM3MbN1ssklM13daSiYhGJqZ2bq5RqZOOCltXOYkk9IMzdzs3FyySUySSVCimZudm2l05oSTssYmTjIpy9DMzsbNM/61FV6FQVGSSUyGZn72bZ4JgZNNShqfN8mkJEMzP/s2y6S8CSflTEmbZFKOoVmAbZtFNglKoROToVmAbZtjN1XtBbMVkklMhmYJdm0O2SQoySQmQ7MEuwYADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANAAhQ4ADVDoANCA/x8WaeU0lVMwjgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit the SEM model\n",
    "ro.r('fit5 <- sem(lcsm1, data=fairplayer, meanstructure=TRUE)')\n",
    "\n",
    "# Display the summary of the SEM model\n",
    "summary = ro.r('summary(fit5, fit.measures=TRUE, standardized=TRUE)')\n",
    "print(summary)\n",
    "\n",
    "# Save the SEM path diagram as a PNG file\n",
    "ro.r('''\n",
    "png(\"../LSCM_and_GCM/Datasets/semPath5.png\", width = 2000, height = 1200, res = 150)\n",
    "semPaths(fit5)\n",
    "dev.off()\n",
    "''')\n",
    "\n",
    "# Display the saved SEM path diagram in Jupyter Notebook\n",
    "display(Image(filename=\"../LSCM_and_GCM/Datasets/semPath5.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Interpretation of the Latent Change Score Model\n",
    "\n",
    "**Model Fit:**\n",
    "The first and most critical step is to assess the model fit. Based on conventional standards, the fit of this model is **poor**.\n",
    "\n",
    "* The **Chi-Square test** is significant (χ²(8) = 51.469, p < 0.001), which is an initial indication of misfit.\n",
    "* The **CFI (0.870)** and **TLI (0.756)** are well below the acceptable threshold of >0.90, suggesting the model does not replicate the relationships in the data well.\n",
    "* The **RMSEA is 0.213**, which is very high and indicates a poor approximation of the data (a good RMSEA is typically < 0.08).\n",
    "* The only acceptable index is the **SRMR (0.063)**.\n",
    "\n",
    "Given the poor overall fit, we must be **cautious** when interpreting the specific parameters below. A poor fit suggests that the model's underlying assumptions (e.g., the measurement structure of empathy, the nature of the change) may not be appropriate for this dataset.\n",
    "\n",
    "**Means of the Latent Factors (The Intercepts):**\n",
    "This section describes the average starting point and average change.\n",
    "* The mean of the latent factor **`emp1`** is **3.883**. This is the estimated average level of latent empathy at the first time point.\n",
    "* The mean of the latent **`change`** factor is **0.083**. While this suggests a small positive increase in empathy on average, this result is **not statistically significant** (p = 0.238). The primary conclusion here is that we have no statistical evidence of a systematic, average change in empathy for the group as a whole between the two time points.\n",
    "\n",
    "**Variances of the Latent Factors:**\n",
    "The variances show the degree of individual differences.\n",
    "* The variance for the initial latent state (`emp1` = 0.235) is significant, meaning that students started with meaningfully different levels of empathy.\n",
    "* The variance for the latent `change` factor (0.095) is also significant. This is an interesting finding. It means that even though the *average* change for the group was not significant, there were still significant individual differences in how empathy changed. Some students likely increased, others decreased, and these changes canceled each other out on average.\n",
    "\n",
    "**Key LSCM Parameters:**\n",
    "* **Covariance (`emp1 ~~ change`):** The covariance between the initial empathy level and the change factor is **-0.036**. This parameter is **not statistically significant** (p = 0.370). This indicates that a student's initial level of empathy was not significantly related to how much their empathy changed over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Refining the Model: Measurement Invariance and Correlated Residuals\n",
    "\n",
    "The initial Latent Change Score Model was a good start, but it rested on strong assumptions. To build a more robust and methodologically sound model, we will now introduce two crucial refinements: formally testing for **measurement invariance** and accounting for **correlated residuals**.\n",
    "\n",
    "#### Measurement Invariance (MI)\n",
    "\n",
    "This is a critical concept for any longitudinal analysis.\n",
    "\n",
    "* **What it is:** Measurement invariance is the statistical property that ensures our measurement instrument (the empathy scale) is measuring the **same underlying construct in the same way** at both time points. To claim that *empathy* has changed, we must first be confident that our *measurement* of empathy is stable.\n",
    "* **How we test it here:** The `lcsm2` model takes the first step by testing for **metric invariance**. It achieves this by constraining the factor loadings for each corresponding item to be equal across time. You can see this in the model syntax:\n",
    "    ```R\n",
    "    emp1 =~ a*sEM01at1 + b*sEM02at1 + ...\n",
    "    emp2 =~ a*sEM01at2 + b*sEM02at2 + ...\n",
    "    ```\n",
    "    The `a*` label forces the factor loading for the item `sEM01` to be the same at both `t1` and `t2` (and likewise for `b*` and `c*`). This tests the assumption that the items relate to the latent empathy construct consistently over time.\n",
    "\n",
    "#### Correlated Residuals\n",
    "\n",
    "The second refinement is adding what are known as correlated residuals or correlated errors.\n",
    "\n",
    "* **What they are:** This refers to modeling the relationship between the measurement errors of the *same item* across time. You can see this specified in the syntax:\n",
    "    ```R\n",
    "    sEM01at1 ~~ sEM01at2\n",
    "    sEM02at1 ~~ sEM02at2\n",
    "    sEM03at1 ~~ sEM03at2\n",
    "    ```\n",
    "* **Why we include them:** We add these paths because we expect that any unique aspect of how a person responds to a specific item (that isn't due to their general empathy) will be somewhat consistent over time. For example, if a person uniquely interprets the phrasing of `sEM01` at `t1`, they will likely have a similar unique interpretation at `t2`. Accounting for this makes the model more realistic and the parameter estimates more accurate.\n",
    "\n",
    "The `lcsm2` model below therefore represents a more sophisticated and appropriate model for analyzing this longitudinal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lavaan 0.6-19 ended normally after 61 iterations\n",
      "\n",
      "  Estimator                                         ML\n",
      "  Optimization method                           NLMINB\n",
      "  Number of model parameters                        22\n",
      "  Number of equality constraints                     2\n",
      "\n",
      "                                                  Used       Total\n",
      "  Number of observations                           120         143\n",
      "\n",
      "Model Test User Model:\n",
      "                                                      \n",
      "  Test statistic                                 8.291\n",
      "  Degrees of freedom                                 7\n",
      "  P-value (Chi-square)                           0.308\n",
      "\n",
      "Model Test Baseline Model:\n",
      "\n",
      "  Test statistic                               348.774\n",
      "  Degrees of freedom                                15\n",
      "  P-value                                        0.000\n",
      "\n",
      "User Model versus Baseline Model:\n",
      "\n",
      "  Comparative Fit Index (CFI)                    0.996\n",
      "  Tucker-Lewis Index (TLI)                       0.992\n",
      "\n",
      "Loglikelihood and Information Criteria:\n",
      "\n",
      "  Loglikelihood user model (H0)               -648.716\n",
      "  Loglikelihood unrestricted model (H1)       -644.571\n",
      "                                                      \n",
      "  Akaike (AIC)                                1337.432\n",
      "  Bayesian (BIC)                              1393.182\n",
      "  Sample-size adjusted Bayesian (SABIC)       1329.952\n",
      "\n",
      "Root Mean Square Error of Approximation:\n",
      "\n",
      "  RMSEA                                          0.039\n",
      "  90 Percent confidence interval - lower         0.000\n",
      "  90 Percent confidence interval - upper         0.123\n",
      "  P-value H_0: RMSEA <= 0.050                    0.502\n",
      "  P-value H_0: RMSEA >= 0.080                    0.270\n",
      "\n",
      "Standardized Root Mean Square Residual:\n",
      "\n",
      "  SRMR                                           0.043\n",
      "\n",
      "Parameter Estimates:\n",
      "\n",
      "  Standard errors                             Standard\n",
      "  Information                                 Expected\n",
      "  Information saturated (h1) model          Structured\n",
      "\n",
      "Latent Variables:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n",
      "  emp1 =~                                                               \n",
      "    sEM01at1   (a)    1.000                               0.482    0.665\n",
      "    sEM02at1   (b)    1.210    0.142    8.498    0.000    0.583    0.780\n",
      "    sEM03at1   (c)    1.394    0.165    8.466    0.000    0.672    0.820\n",
      "  emp2 =~                                                               \n",
      "    sEM01at2   (a)    1.000                               0.479    0.698\n",
      "    sEM02at2   (b)    1.210    0.142    8.498    0.000    0.579    0.805\n",
      "    sEM03at2   (c)    1.394    0.165    8.466    0.000    0.667    0.785\n",
      "  change =~                                                             \n",
      "    emp2              1.000                               0.731    0.731\n",
      "\n",
      "Regressions:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n",
      "  emp2 ~                                                                \n",
      "    emp1              1.000                               1.007    1.007\n",
      "\n",
      "Covariances:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n",
      "  emp1 ~~                                                               \n",
      "    change           -0.063    0.026   -2.453    0.014   -0.373   -0.373\n",
      " .sEM01at1 ~~                                                           \n",
      "   .sEM01at2          0.159    0.033    4.747    0.000    0.159    0.595\n",
      " .sEM02at1 ~~                                                           \n",
      "   .sEM02at2          0.038    0.031    1.226    0.220    0.038    0.192\n",
      " .sEM03at1 ~~                                                           \n",
      "   .sEM03at2          0.049    0.040    1.214    0.225    0.049    0.199\n",
      "\n",
      "Intercepts:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n",
      "   .sEM01at2          0.000                               0.000    0.000\n",
      "   .sEM01at1          0.000                               0.000    0.000\n",
      "    change            0.083    0.053    1.563    0.118    0.238    0.238\n",
      "    emp1              3.883    0.066   58.629    0.000    8.052    8.052\n",
      "   .sEM02at1         -0.911    0.558   -1.634    0.102   -0.911   -1.219\n",
      "   .sEM03at1         -1.645    0.644   -2.553    0.011   -1.645   -2.008\n",
      "   .sEM02at2         -1.054    0.569   -1.853    0.064   -1.054   -1.465\n",
      "   .sEM03at2         -1.707    0.658   -2.596    0.009   -1.707   -2.007\n",
      "\n",
      "Variances:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n",
      "   .emp2              0.000                               0.000    0.000\n",
      "   .sEM01at1          0.294    0.045    6.480    0.000    0.294    0.558\n",
      "   .sEM02at1          0.219    0.045    4.839    0.000    0.219    0.391\n",
      "   .sEM03at1          0.220    0.054    4.080    0.000    0.220    0.327\n",
      "   .sEM01at2          0.242    0.039    6.208    0.000    0.242    0.513\n",
      "   .sEM02at2          0.182    0.041    4.476    0.000    0.182    0.352\n",
      "   .sEM03at2          0.278    0.058    4.839    0.000    0.278    0.385\n",
      "    emp1              0.233    0.055    4.244    0.000    1.000    1.000\n",
      "    change            0.123    0.031    3.952    0.000    1.000    1.000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the SEM model\n",
    "ro.r('''\n",
    "lcsm2 <- '\n",
    "\n",
    "# Defining a latent variable representing empathy at time 1 \n",
    "emp1 =~ a*sEM01at1 + b*sEM02at1 + c*sEM03at1 \n",
    "\n",
    "# Defining a latent variable representing empathy at time 2\n",
    "# a*, b* and c* indicate that the loading of the same indicator over time is fixed to equivalence with time 1\n",
    "emp2 =~ a*sEM01at2 + b*sEM02at2 + c*sEM03at2 \n",
    "\n",
    "# Fixing the loading of the change score to 1\n",
    "change =~ 1*emp2\n",
    "\n",
    "#Fixing the regression of time 2 on time 1 empathy to 1\n",
    "emp2 ~ 1*emp1\n",
    "\n",
    "#Fixing the residual variance of the post-intervention score to 0\n",
    "emp2 ~~ 0 * emp2  \n",
    "\n",
    "#Fixing the intercept of one indicator per timepoint to 0 in order to identify the mean structure\n",
    "sEM01at2 ~ 0*1\n",
    "sEM01at1 ~ 0*1\n",
    "\n",
    "# Freely estimate phantom variable and baseline means. Per default, lavaan would fix them to 0\n",
    "change ~ 1 \n",
    "emp1 ~ 1\n",
    "\n",
    "# Include covariance between change score variable and baseline\n",
    "change ~~ emp1\n",
    "\n",
    "# Autoregressive effects\n",
    "\n",
    "sEM01at1 ~~ sEM01at2\n",
    "sEM02at1 ~~ sEM02at2\n",
    "sEM03at1 ~~ sEM03at2\n",
    "'\n",
    "''')\n",
    "\n",
    "\n",
    "# Fit the SEM model\n",
    "ro.r('fit6 <- sem(lcsm2, data=fairplayer, meanstructure=TRUE)')\n",
    "\n",
    "# Display the summary of the SEM model\n",
    "summary = ro.r('summary(fit6, fit.measures=TRUE, standardized=TRUE)')\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Interpretation of the Refined LSCM\n",
    "\n",
    "**Model Fit:**\n",
    "The fit of this refined model is **excellent**. This is a crucial finding, as it suggests that the new constraints we added (metric invariance and correlated residuals) have resulted in a model that represents the data very well.\n",
    "\n",
    "Given this strong fit, we can interpret the model's parameters with a high degree of confidence.\n",
    "\n",
    "**Measurement Invariance:**\n",
    "A key feature of this model was the test for **metric invariance**, implemented by constraining the factor loadings to be equal across time (e.g., `a*`, `b*`, `c*`). Because the model achieved excellent fit *with* these constraints in place, we have strong evidence that metric invariance holds. This is a very important conclusion: it means that the empathy indicators relate to the latent empathy construct in the same way at both time points. This gives us a solid foundation for interpreting the change itself.\n",
    "\n",
    "**Means of the Latent Factors (The Intercepts):**\n",
    "* The mean of the latent factor **`emp1`** is **3.883**. This is the average level of latent empathy for the sample at `t1`.\n",
    "* The mean of the latent **`change`** factor is **0.083**. This average change is **not statistically significant** (p = 0.118). Therefore, despite the positive estimate, we cannot conclude there was a systematic average increase or decrease in empathy for the group as a whole.\n",
    "\n",
    "**Variances of the Latent Factors:**\n",
    "* The variances for the initial latent state (`emp1` = 0.233) and the latent change score (`change` = 0.123) are both statistically significant (p < 0.001). This tells us that there are meaningful individual differences in both the starting levels of empathy and in the amount that empathy changed from `t1` to `t2`.\n",
    "\n",
    "**Key LSCM Parameters (Covariances):**\n",
    "This section contains some of the most important findings of the refined model.\n",
    "* **Covariance (`emp1 ~~ change`):** The covariance between the initial state (`emp1`) and the change factor (`change`) is **-0.063**, and this relationship is **statistically significant** (p = 0.014). This is a key finding that was not apparent in the previous, poorly-fitting model. The significant negative value means that the initial level of empathy is predictive of the subsequent change. Specifically, individuals who started with higher levels of empathy tended to show less positive change in empathy over time.\n",
    "* **Correlated Residuals:** The model allowed the errors of the same items to correlate over time. The error for the first item (`sEM01at1 ~~ sEM01at2`) was significantly correlated (p < 0.001), justifying its inclusion and suggesting this item has a stable uniqueness not captured by the general empathy factor. The other two were not significant, but including them as a set contributed to the overall excellent model fit."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psy112ER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
